{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General information\n",
    "\n",
    "In this kernel I work with IEEE Fraud Detection competition.\n",
    "\n",
    "EEE-CIS works across a variety of AI and machine learning areas, including deep neural networks, fuzzy systems, evolutionary computation, and swarm intelligence. Today they’re partnering with the world’s leading payment service company, Vesta Corporation, seeking the best solutions for fraud prevention industry, and now you are invited to join the challenge.\n",
    "\n",
    "We have a binary classification problem with a heavy imbalance which is an inherent property of such problems.\n",
    "At first I'll explore the data and try to find valuable insights, maybe I'll do some feature engineering and then it wil be time to build models.\n",
    "\n",
    "![](https://cis.ieee.org/images/files/slideshow/abstract01.jpg)\n",
    "\n",
    "*Work in progress*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "!pip install -U vega_datasets notebook vega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelstanley/.virtualenvs/datasci/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import eli5\n",
    "import shap\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import altair as alt\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "alt.renderers.enable('notebook')\n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used in this kernel\n",
    "They are in the hidden cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>    requirejs.config({\n",
       "        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
       "        paths: {'vega': 'https://cdn.jsdelivr.net/npm/vega@v5.4.0?noext', 'vega-lib': 'https://cdn.jsdelivr.net/npm/vega-lib?noext', 'vega-lite': 'https://cdn.jsdelivr.net/npm/vega-lite@v3.3.0?noext', 'vega-embed': 'https://cdn.jsdelivr.net/npm/vega-embed@3?noext'}\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import altair as alt\n",
    "from altair.vega import v5\n",
    "from IPython.display import HTML\n",
    "\n",
    "# using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\n",
    "def prepare_altair():\n",
    "    \"\"\"\n",
    "    Helper function to prepare altair for working.\n",
    "    \"\"\"\n",
    "\n",
    "    vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\n",
    "    vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n",
    "    vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n",
    "    vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n",
    "    noext = \"?noext\"\n",
    "    \n",
    "    paths = {\n",
    "        'vega': vega_url + noext,\n",
    "        'vega-lib': vega_lib_url + noext,\n",
    "        'vega-lite': vega_lite_url + noext,\n",
    "        'vega-embed': vega_embed_url + noext\n",
    "    }\n",
    "    \n",
    "    workaround = f\"\"\"    requirejs.config({{\n",
    "        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
    "        paths: {paths}\n",
    "    }});\n",
    "    \"\"\"\n",
    "    \n",
    "    return workaround\n",
    "    \n",
    "\n",
    "def add_autoincrement(render_func):\n",
    "    # Keep track of unique <div/> IDs\n",
    "    cache = {}\n",
    "    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n",
    "        if autoincrement:\n",
    "            if id in cache:\n",
    "                counter = 1 + cache[id]\n",
    "                cache[id] = counter\n",
    "            else:\n",
    "                cache[id] = 0\n",
    "            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n",
    "        else:\n",
    "            if id not in cache:\n",
    "                cache[id] = 0\n",
    "            actual_id = id\n",
    "        return render_func(chart, id=actual_id)\n",
    "    # Cache will stay outside and \n",
    "    return wrapped\n",
    "           \n",
    "\n",
    "@add_autoincrement\n",
    "def render(chart, id=\"vega-chart\"):\n",
    "    \"\"\"\n",
    "    Helper function to plot altair visualizations.\n",
    "    \"\"\"\n",
    "    chart_str = \"\"\"\n",
    "    <div id=\"{id}\"></div><script>\n",
    "    require([\"vega-embed\"], function(vg_embed) {{\n",
    "        const spec = {chart};     \n",
    "        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n",
    "        console.log(\"anything?\");\n",
    "    }});\n",
    "    console.log(\"really...anything?\");\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    return HTML(\n",
    "        chart_str.format(\n",
    "            id=id,\n",
    "            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "    \n",
    "\n",
    "@jit\n",
    "def fast_auc(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc\n",
    "\n",
    "\n",
    "def eval_auc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast auc eval function for lgb.\n",
    "    \"\"\"\n",
    "    return 'auc', fast_auc(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    \"\"\"\n",
    "    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n",
    "    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n",
    "    \"\"\"\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
    "    \n",
    "\n",
    "def train_model_regression(X, X_test, y, params, folds=None, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3):\n",
    "    \"\"\"\n",
    "    A function to train a variety of regression models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    splits = folds.split(X) if splits is None else splits\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'sklearn_scoring_function': metrics.mean_absolute_error},\n",
    "                    'group_mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'scoring_function': group_mean_log_mae},\n",
    "                    'mse': {'lgb_metric_name': 'mse',\n",
    "                        'catboost_metric_name': 'MSE',\n",
    "                        'sklearn_scoring_function': metrics.mean_squared_error}\n",
    "                    }\n",
    "\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        if verbose:\n",
    "            print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        if eval_metric != 'group_mae':\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "        else:\n",
    "            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_splits\n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict\n",
    "    \n",
    "\n",
    "\n",
    "def train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3, averaging='usual', n_jobs=-1):\n",
    "    \"\"\"\n",
    "    A function to train a variety of classification models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n",
    "                        'catboost_metric_name': 'AUC',\n",
    "                        'sklearn_scoring_function': metrics.roc_auc_score},\n",
    "                    }\n",
    "    \n",
    "    result_dict = {}\n",
    "    if averaging == 'usual':\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros((len(X), 1))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros((len(X_test), 1))\n",
    "        \n",
    "    elif averaging == 'rank':\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros((len(X), 1))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros((len(X_test), 1))\n",
    "\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = n_jobs)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        if averaging == 'usual':\n",
    "            \n",
    "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "            \n",
    "            prediction += y_pred.reshape(-1, 1)\n",
    "\n",
    "        elif averaging == 'rank':\n",
    "                                  \n",
    "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "                                  \n",
    "            prediction += pd.Series(y_pred).rank().values.reshape(-1, 1)        \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "            result_dict['top_columns'] = cols\n",
    "        \n",
    "    return result_dict\n",
    "\n",
    "# setting up altair\n",
    "workaround = prepare_altair()\n",
    "HTML(\"\".join((\n",
    "    \"<script>\",\n",
    "    workaround,\n",
    "    \"</script>\",\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and overview\n",
    "\n",
    "Data is separated into two datasets: information about the identity of the customer and transaction information. Not all transactions belong to identities, which are available. Maybe it would be possible to use additional transactions to generate new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity = pd.read_csv('train_identity.csv')\n",
    "train_transaction = pd.read_csv('train_transaction.csv')\n",
    "#test_identity = pd.read_csv(f'{folder_path}test_identity.csv')\n",
    "#test_transaction = pd.read_csv(f'{folder_path}test_transaction.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "# let's combine the data and work with the whole dataset\n",
    "train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "#test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset has 590540 rows and 434 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\n",
    "#print(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have two medium-sized datasets with a lot of columns. Train and test data have similar number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductCD\n",
       "C    0.116872692245946\n",
       "H    0.047662306201550\n",
       "R    0.037825937027507\n",
       "S    0.058995528035776\n",
       "W    0.020399390451930\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['isFraud'].groupby(by=train['ProductCD']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train['ProductCD'].unique()\n",
    "fraud_rate = train['isFraud'].groupby(by=train['ProductCD']).mean()\n",
    "for val in x:\n",
    "sum(train[train[=val])\n",
    "plt.bar(x,fraud_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionID: 590540\n",
      "[2987000 2987001 2987002 2987003 2987004 2987005 2987006 2987007 2987008\n",
      " 2987009 2987010 2987011 2987012 2987013 2987014 2987015 2987016 2987017\n",
      " 2987018 2987019]\n",
      "\n",
      "\n",
      "isFraud: 2\n",
      "[0 1]\n",
      "\n",
      "\n",
      "TransactionDT: 573349\n",
      "[86400 86401 86469 86499 86506 86510 86522 86529 86535 86536 86549 86555\n",
      " 86564 86585 86596 86618 86620 86668 86725 86730]\n",
      "\n",
      "\n",
      "TransactionAmt: 20902\n",
      "[ 68.5    29.     59.     50.     49.    159.    422.5    15.    117.\n",
      "  75.887  16.495  40.     10.5    57.95   30.    100.     47.95  186.\n",
      "  39.    159.95 ]\n",
      "\n",
      "\n",
      "ProductCD: 5\n",
      "['W' 'H' 'C' 'S' 'R']\n",
      "\n",
      "\n",
      "card1: 13553\n",
      "[13926  2755  4663 18132  4497  5937 12308 12695  2803 17399 16496  4461\n",
      "  3786 12866 11839  7055  1790 11492  7005  7875]\n",
      "\n",
      "\n",
      "card2: 500\n",
      "[ nan 404. 490. 567. 514. 555. 360. 100. 111. 352. 375. 418. 303. 314.\n",
      " 543. 583. 148. 321. 269. 361.]\n",
      "\n",
      "\n",
      "card3: 114\n",
      "[150. 117. 185. 143. 144. 163. 146. 191. 162. 119. 147. 100. 135. 137.\n",
      " 138. 102. 213. 106. 214. 148.]\n",
      "\n",
      "\n",
      "card4: 4\n",
      "['discover' 'mastercard' 'visa' 'american express' nan]\n",
      "\n",
      "\n",
      "card5: 119\n",
      "[142. 102. 166. 117. 226. 224. 134. 219. 137. 195. 138. 100. 147. 162.\n",
      " 202. 118. 150. 183. 171. 236.]\n",
      "\n",
      "\n",
      "card6: 4\n",
      "['credit' 'debit' nan 'debit or credit' 'charge card']\n",
      "\n",
      "\n",
      "addr1: 332\n",
      "[315. 325. 330. 476. 420. 272. 126. 337. 204.  nan 226. 170. 184. 264.\n",
      " 299. 441. 472. 251. 469. 191.]\n",
      "\n",
      "\n",
      "addr2: 74\n",
      "[ 87.  nan  96.  35.  60.  98.  43.  65.  32.  13.  31. 101.  24.  16.\n",
      "  15.  19.  71.  59. 102.  44.]\n",
      "\n",
      "\n",
      "dist1: 2651\n",
      "[ 19.  nan 287.  36.   0.   3.   5.   4.  17.  13.   2. 664.  20.   6.\n",
      "  30.  16.  80.   7. 154.   1.]\n",
      "\n",
      "\n",
      "dist2: 1751\n",
      "[ nan  30.  98. 149.  84. 100. 744. 109.   7.   6. 174. 317.  73. 240.\n",
      "   4.  70.   2.   0.  99. 425.]\n",
      "\n",
      "\n",
      "P_emaildomain: 59\n",
      "[nan 'gmail.com' 'outlook.com' 'yahoo.com' 'mail.com' 'anonymous.com'\n",
      " 'hotmail.com' 'verizon.net' 'aol.com' 'me.com' 'comcast.net'\n",
      " 'optonline.net' 'cox.net' 'charter.net' 'rocketmail.com' 'prodigy.net.mx'\n",
      " 'embarqmail.com' 'icloud.com' 'live.com.mx' 'gmail']\n",
      "\n",
      "\n",
      "R_emaildomain: 60\n",
      "[nan 'gmail.com' 'hotmail.com' 'outlook.com' 'anonymous.com' 'charter.net'\n",
      " 'prodigy.net.mx' 'comcast.net' 'live.com.mx' 'icloud.com' 'yahoo.com'\n",
      " 'aol.com' 'juno.com' 'att.net' 'verizon.net' 'yahoo.com.mx'\n",
      " 'bellsouth.net' 'servicios-ta.com' 'ymail.com' 'hotmail.es']\n",
      "\n",
      "\n",
      "C1: 1657\n",
      "[  1.   2.   4.   6. 127.   3.   8.  92. 190.   5.  12.   7. 202.  21.\n",
      " 131.  16.  25.   0.   9. 199.]\n",
      "\n",
      "\n",
      "C2: 1216\n",
      "[  1.   5.   2.   4. 120.  86. 145.   6.  11. 208.   3. 153.  25.   7.\n",
      "  16.  20.  13. 183.  44.   9.]\n",
      "\n",
      "\n",
      "C3: 27\n",
      "[ 0.  1.  8.  3.  2. 16.  4.  9. 10. 12. 11. 13. 14. 15. 17. 18. 19. 20.\n",
      " 21. 22.]\n",
      "\n",
      "\n",
      "C4: 1260\n",
      "[  0.   1.   2.   3.   4.  46.  47.  48.  21.   5.  10.  12. 534. 536.\n",
      "  29. 537.  13.  32.  27.   7.]\n",
      "\n",
      "\n",
      "C5: 319\n",
      "[  0.   2.   1. 168.   3. 121. 142.   5.   6. 128. 118.  33.   4. 103.\n",
      "   7.  10.  17.   8. 123. 111.]\n",
      "\n",
      "\n",
      "C6: 1328\n",
      "[  1.   4.   3.   5.   7.  99.   2.   0.   6.  72. 147. 181. 128.  22.\n",
      " 101.  12.  17. 139. 122.  68.]\n",
      "\n",
      "\n",
      "C7: 1103\n",
      "[ 0.  1.  2.  4. 46.  3. 47. 48. 10. 29. 13. 32. 27.  7.  5. 20.  9. 33.\n",
      "  6. 34.]\n",
      "\n",
      "\n",
      "C8: 1253\n",
      "[  0.   1.   6.   2.   5.  13.   4.  49.  12.   3.  10.   9.   7.   8.\n",
      "  38.  24. 349. 350.  32. 352.]\n",
      "\n",
      "\n",
      "C9: 205\n",
      "[  1.   0.   3.   2.  81.   4.  76. 129.   9.  64. 114.  17.   6.  79.\n",
      "  14.   5.  97.  43.  13.   8.]\n",
      "\n",
      "\n",
      "C10: 1231\n",
      "[  0.   1.  93.   2.  11. 104.   3.  31.  15.   5.   8.  14.   7.  10.\n",
      "   4.  25.  22.   6.  58.  16.]\n",
      "\n",
      "\n",
      "C11: 1476\n",
      "[  2.   1.   5.   3.  80.   4.  73. 132.   9. 182. 134.  19.   8.  94.\n",
      "  13.  18.   6.   7. 154.  98.]\n",
      "\n",
      "\n",
      "C12: 1199\n",
      "[ 0.  2.  1.  4.  3.  5. 10.  8. 33. 71. 31.  7. 18. 13. 22.  6.  9. 11.\n",
      " 24. 19.]\n",
      "\n",
      "\n",
      "C13: 1597\n",
      "[  1.  25.  12.   2.   6.  24.  22. 673.  10.   5.   4.  19.  11.  18.\n",
      " 498.  96.   3. 527.  34.  23.]\n",
      "\n",
      "\n",
      "C14: 1108\n",
      "[  1.   2.   3.   6. 111.   5.  79. 148.   7.   4.  10. 108.   0. 155.\n",
      "  18. 105.  19.   9. 173. 106.]\n",
      "\n",
      "\n",
      "D1: 641\n",
      "[ 14.   0. 112.  61.   1.  72.  46.  62. 485.  66. 169.  29. 121. 245.\n",
      " 201. 478. 542. 181.  91.   3.]\n",
      "\n",
      "\n",
      "D2: 641\n",
      "[ nan 112.  61.   1.  72.  46.  62. 485.  66. 169.  29. 121. 245. 201.\n",
      " 478. 542. 181.  68.   3. 108.]\n",
      "\n",
      "\n",
      "D3: 649\n",
      "[ 13.  nan   0.  30.  11.  10.   2.   3.  35.  56.   1. 121. 245.  86.\n",
      " 210.  23. 107.  65.  28.  20.]\n",
      "\n",
      "\n",
      "D4: 808\n",
      "[ nan   0.  94. 318. 107.  45.  35. 358.  65.  24. 244. 391. 259. 400.\n",
      " 290. 477.  22. 289. 365.  20.]\n",
      "\n",
      "\n",
      "D5: 688\n",
      "[ nan   0.  30.  11.  10.   2.  40.  35.   1.  90.  56. 121. 200. 109.\n",
      "  22.  46. 107.  20. 222.  39.]\n",
      "\n",
      "\n",
      "D6: 829\n",
      "[ nan   0. 537.  35. 216. 163. 398.  24. 338.  18.  55. 242.  42. 318.\n",
      "  46. 348. 566.   1.  28. 289.]\n",
      "\n",
      "\n",
      "D7: 597\n",
      "[ nan   0.   4.   8. 163.  48.  24.  11.  18.  16. 242.  42. 318.  46.\n",
      " 102.   3.   1.  28.  43. 104.]\n",
      "\n",
      "\n",
      "D8: 12353\n",
      "[ nan  83.  26.  21.  29. 189. 126. 777.  12. 255.   0.   7.   4. 128.\n",
      "   2.  94. 766.  81. 549. 140.]\n",
      "\n",
      "\n",
      "D9: 24\n",
      "[       nan 0.         0.041666   0.083333   0.125      0.166666\n",
      " 0.208333   0.25       0.291666   0.33333299 0.416666   0.45833299\n",
      " 0.5        0.54166597 0.58333302 0.625      0.66666597 0.70833302\n",
      " 0.75       0.79166597]\n",
      "\n",
      "\n",
      "D10: 818\n",
      "[ 13.   0.  84.  nan  40. 107.  45. 465.  50. 485.  26. 244. 264.  28.\n",
      " 121. 245. 290. 520. 181. 289.]\n",
      "\n",
      "\n",
      "D11: 676\n",
      "[ 13.  nan 315.   0. 302. 423. 237.  35. 245. 446.  22. 358. 289.   2.\n",
      " 259. 294. 426.  12. 104. 435.]\n",
      "\n",
      "\n",
      "D12: 635\n",
      "[ nan   0.  35. 163. 398.  24. 338.  18. 242.  42. 318. 348.   1.  28.\n",
      " 289. 346.  60.   2.  75. 260.]\n",
      "\n",
      "\n",
      "D13: 577\n",
      "[ nan   0.  24.  18.  21.  58. 367.  47. 289.  60. 229. 245.   1.  90.\n",
      "  75. 119.  56.   2.  71. 210.]\n",
      "\n",
      "\n",
      "D14: 802\n",
      "[ nan   0.  98.  97.   2.  18.  50. 386. 301. 337.  46.  87. 164. 298.\n",
      " 244. 369. 123. 368.  21.  13.]\n",
      "\n",
      "\n",
      "D15: 859\n",
      "[  0. 315. 111.  nan 318. 107.  45.  62. 109.  65.  26. 244. 391. 259.\n",
      " 121. 245. 290. 477. 541. 389.]\n",
      "\n",
      "\n",
      "M1: 2\n",
      "['T' nan 'F']\n",
      "\n",
      "\n",
      "M2: 2\n",
      "['T' nan 'F']\n",
      "\n",
      "\n",
      "M3: 2\n",
      "['T' nan 'F']\n",
      "\n",
      "\n",
      "M4: 3\n",
      "['M2' 'M0' nan 'M1']\n",
      "\n",
      "\n",
      "M5: 2\n",
      "['F' 'T' nan]\n",
      "\n",
      "\n",
      "M6: 2\n",
      "['T' 'F' nan]\n",
      "\n",
      "\n",
      "M7: 2\n",
      "[nan 'F' 'T']\n",
      "\n",
      "\n",
      "M8: 2\n",
      "[nan 'F' 'T']\n",
      "\n",
      "\n",
      "M9: 2\n",
      "[nan 'F' 'T']\n",
      "\n",
      "\n",
      "V1: 2\n",
      "[ 1. nan  0.]\n",
      "\n",
      "\n",
      "V2: 9\n",
      "[ 1. nan  2.  3.  0.  4.  5.  6.  7.  8.]\n",
      "\n",
      "\n",
      "V3: 10\n",
      "[ 1. nan  2.  3.  0.  4.  5.  6.  7.  8.  9.]\n",
      "\n",
      "\n",
      "V4: 7\n",
      "[ 1. nan  2.  0.  3.  4.  5.  6.]\n",
      "\n",
      "\n",
      "V5: 7\n",
      "[ 1. nan  2.  0.  3.  4.  5.  6.]\n",
      "\n",
      "\n",
      "V6: 10\n",
      "[ 1. nan  2.  3.  0.  4.  5.  6.  7.  9.  8.]\n",
      "\n",
      "\n",
      "V7: 10\n",
      "[ 1. nan  2.  3.  0.  4.  5.  6.  7.  9.  8.]\n",
      "\n",
      "\n",
      "V8: 9\n",
      "[ 1. nan  2.  3.  0.  6.  4.  5.  8.  7.]\n",
      "\n",
      "\n",
      "V9: 9\n",
      "[ 1. nan  2.  3.  0.  4.  6.  5.  8.  7.]\n",
      "\n",
      "\n",
      "V10: 5\n",
      "[ 0. nan  1.  2.  3.  4.]\n",
      "\n",
      "\n",
      "V11: 6\n",
      "[ 0. nan  1.  2.  4.  3.  5.]\n",
      "\n",
      "\n",
      "V12: 4\n",
      "[ 1.  0. nan  2.  3.]\n",
      "\n",
      "\n",
      "V13: 7\n",
      "[ 1.  0. nan  2.  3.  4.  5.  6.]\n",
      "\n",
      "\n",
      "V14: 2\n",
      "[ 1. nan  0.]\n",
      "\n",
      "\n",
      "V15: 8\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V16: 15\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  8.  9. 11.  7. 10. 13. 14. 15.]\n",
      "\n",
      "\n",
      "V17: 16\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "\n",
      "\n",
      "V18: 16\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "\n",
      "\n",
      "V19: 8\n",
      "[ 1. nan  0.  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V20: 15\n",
      "[ 1. nan  2.  0.  3.  4.  5.  6.  8.  9. 11.  7. 10. 13. 14. 15.]\n",
      "\n",
      "\n",
      "V21: 6\n",
      "[ 0. nan  1.  2.  3.  5.  4.]\n",
      "\n",
      "\n",
      "V22: 9\n",
      "[ 0. nan  1.  2.  3.  4.  7.  5.  6.  8.]\n",
      "\n",
      "\n",
      "V23: 14\n",
      "[ 1. nan  2.  3.  0.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "\n",
      "\n",
      "V24: 14\n",
      "[ 1. nan  3.  2.  0.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
      "\n",
      "\n",
      "V25: 7\n",
      "[ 1. nan  2.  0.  3.  4.  5.  7.]\n",
      "\n",
      "\n",
      "V26: 13\n",
      "[ 1. nan  2.  0.  3.  4.  5.  6.  7.  8.  9. 10. 11. 13.]\n",
      "\n",
      "\n",
      "V27: 4\n",
      "[ 0. nan  1.  2.  4.]\n",
      "\n",
      "\n",
      "V28: 4\n",
      "[ 0. nan  1.  2.  4.]\n",
      "\n",
      "\n",
      "V29: 6\n",
      "[ 0. nan  1.  2.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V30: 8\n",
      "[ 0. nan  1.  2.  4.  5.  3.  6.  9.]\n",
      "\n",
      "\n",
      "V31: 8\n",
      "[ 0. nan  1.  3.  2.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V32: 15\n",
      "[ 0. nan  1.  3.  2.  4.  5.  6.  8.  9. 11.  7. 10. 13. 14. 15.]\n",
      "\n",
      "\n",
      "V33: 7\n",
      "[ 0. nan  1.  2.  3.  4.  5.  7.]\n",
      "\n",
      "\n",
      "V34: 13\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 13.]\n",
      "\n",
      "\n",
      "V35: 4\n",
      "[nan  0.  1.  2.  3.]\n",
      "\n",
      "\n",
      "V36: 6\n",
      "[nan  0.  1.  2.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V37: 55\n",
      "[nan  1.  4.  5.  2.  3.  6.  9.  0.  7.  8. 10. 11. 12. 13. 14. 15. 25.\n",
      " 16. 17.]\n",
      "\n",
      "\n",
      "V38: 55\n",
      "[nan  1.  4.  2.  5.  3.  6.  9. 10.  0. 11. 12. 13.  7. 14.  8. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V39: 16\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "\n",
      "\n",
      "V40: 18\n",
      "[nan  0.  1.  2.  7.  3.  4.  5.  6.  8.  9. 10. 14. 11. 12. 13. 23. 24.\n",
      " 15.]\n",
      "\n",
      "\n",
      "V41: 2\n",
      "[nan  1.  0.]\n",
      "\n",
      "\n",
      "V42: 9\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.]\n",
      "\n",
      "\n",
      "V43: 9\n",
      "[nan  0.  1.  2.  3.  5.  6.  4.  7.  8.]\n",
      "\n",
      "\n",
      "V44: 49\n",
      "[nan  1.  2.  3.  4.  0.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 24. 15.\n",
      " 16. 17.]\n",
      "\n",
      "\n",
      "V45: 49\n",
      "[nan  1.  2.  3.  4.  0.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V46: 7\n",
      "[nan  1.  2.  0.  3.  4.  6.  5.]\n",
      "\n",
      "\n",
      "V47: 9\n",
      "[nan  1.  2.  3.  0.  4.  5.  6.  7. 12.]\n",
      "\n",
      "\n",
      "V48: 6\n",
      "[nan  0.  1.  2.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V49: 6\n",
      "[nan  0.  1.  2.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V50: 6\n",
      "[nan  0.  1.  2.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V51: 7\n",
      "[nan  0.  2.  1.  3.  4.  6.  5.]\n",
      "\n",
      "\n",
      "V52: 9\n",
      "[nan  0.  2.  1.  3.  4.  5.  6.  7. 12.]\n",
      "\n",
      "\n",
      "V53: 6\n",
      "[ 1.  0. nan  2.  3.  5.  4.]\n",
      "\n",
      "\n",
      "V54: 7\n",
      "[ 1.  0. nan  2.  3.  5.  4.  6.]\n",
      "\n",
      "\n",
      "V55: 18\n",
      "[ 1. nan  4.  2.  3.  5.  6.  0.  7.  8.  9. 14. 10. 11. 12. 13. 15. 16.\n",
      " 17.]\n",
      "\n",
      "\n",
      "V56: 52\n",
      "[ 1. nan  4.  2.  3.  5.  6.  0.  9. 10.  7.  8. 11. 12. 13. 14. 15. 24.\n",
      " 29. 16.]\n",
      "\n",
      "\n",
      "V57: 7\n",
      "[ 0. nan  1.  2.  6.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V58: 11\n",
      "[ 0. nan  1.  2.  6.  7.  4.  3.  5.  8.  9. 10.]\n",
      "\n",
      "\n",
      "V59: 17\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 12. 11. 13. 14. 15. 16.]\n",
      "\n",
      "\n",
      "V60: 17\n",
      "[ 0. nan  1.  2.  3.  5.  4.  6.  7.  8.  9. 10. 12. 11. 13. 14. 15. 16.]\n",
      "\n",
      "\n",
      "V61: 7\n",
      "[ 1. nan  0.  2.  3.  6.  4.  5.]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V62: 11\n",
      "[ 1. nan  2.  0.  3.  6.  4.  7.  5.  8.  9. 10.]\n",
      "\n",
      "\n",
      "V63: 8\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V64: 8\n",
      "[ 0. nan  1.  2.  4.  3.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V65: 2\n",
      "[ 1. nan  0.]\n",
      "\n",
      "\n",
      "V66: 8\n",
      "[ 1. nan  2.  0.  5.  3.  4.  6.  7.]\n",
      "\n",
      "\n",
      "V67: 9\n",
      "[ 1. nan  2.  0.  3.  5.  7.  4.  6.  8.]\n",
      "\n",
      "\n",
      "V68: 3\n",
      "[ 0. nan  1.  2.]\n",
      "\n",
      "\n",
      "V69: 6\n",
      "[ 0. nan  1.  2.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V70: 7\n",
      "[ 0. nan  1.  2.  4.  5.  3.  6.]\n",
      "\n",
      "\n",
      "V71: 7\n",
      "[ 0. nan  1.  2.  6.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V72: 11\n",
      "[ 0. nan  1.  2.  6.  3.  7.  4.  5.  8.  9. 10.]\n",
      "\n",
      "\n",
      "V73: 8\n",
      "[ 0. nan  2.  1.  5.  3.  4.  6.  7.]\n",
      "\n",
      "\n",
      "V74: 9\n",
      "[ 0. nan  2.  1.  3.  5.  7.  4.  6.  8.]\n",
      "\n",
      "\n",
      "V75: 5\n",
      "[ 1.  0. nan  2.  3.  4.]\n",
      "\n",
      "\n",
      "V76: 7\n",
      "[ 1.  0. nan  3.  2.  4.  5.  6.]\n",
      "\n",
      "\n",
      "V77: 31\n",
      "[ 1. nan  3.  4.  2.  5.  6.  0.  9. 10.  7.  8. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V78: 32\n",
      "[ 1. nan  3.  2.  4.  5.  6.  0.  9.  7.  8. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V79: 8\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V80: 20\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V81: 20\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V82: 8\n",
      "[ 0.  1. nan  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V83: 8\n",
      "[ 0.  1. nan  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V84: 8\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V85: 8\n",
      "[ 0. nan  1.  2.  3.  5.  4.  6.  7.]\n",
      "\n",
      "\n",
      "V86: 31\n",
      "[ 1. nan  2.  3.  0.  4.  8.  6.  5.  7.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V87: 31\n",
      "[ 1. nan  3.  2.  4.  0.  5.  8.  6.  7.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 19.]\n",
      "\n",
      "\n",
      "V88: 2\n",
      "[ 1. nan  0.]\n",
      "\n",
      "\n",
      "V89: 3\n",
      "[ 0. nan  1.  2.]\n",
      "\n",
      "\n",
      "V90: 6\n",
      "[ 0. nan  1.  2.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V91: 7\n",
      "[ 0. nan  1.  2.  4.  5.  3.  6.]\n",
      "\n",
      "\n",
      "V92: 8\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V93: 8\n",
      "[ 0. nan  1.  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V94: 3\n",
      "[ 0. nan  1.  2.]\n",
      "\n",
      "\n",
      "V95: 881\n",
      "[ 0.  1.  2.  3.  8.  4.  5.  6.  7.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V96: 1410\n",
      "[ 1.  0. 48.  2.  7.  4. 10. 24.  6. 25.  5. 11.  3.  8.  9. 12. 15. 27.\n",
      " 49. 23.]\n",
      "\n",
      "\n",
      "V97: 976\n",
      "[ 0. 28.  2.  1.  3.  8.  9.  4.  5. 12. 11. 29. 30. 31. 32. 33.  6. 34.\n",
      " 35.  7.]\n",
      "\n",
      "\n",
      "V98: 13\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. nan]\n",
      "\n",
      "\n",
      "V99: 89\n",
      "[ 0. 10.  1.  2.  5.  4.  9.  6.  3. 11. 26. 22.  7. 12. 24. 23. 17. 27.\n",
      " 15.  8.]\n",
      "\n",
      "\n",
      "V100: 29\n",
      "[ 0.  4.  1.  2.  3.  5. 10.  6.  8.  7.  9. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V101: 870\n",
      "[ 0.  1.  2.  3.  8.  4.  5.  6.  7.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V102: 1285\n",
      "[ 1.  0. 38.  3. 15. 16.  2.  5.  6.  7. 10. 39. 13.  4. 59. 60. 61. 62.\n",
      " 63. 64.]\n",
      "\n",
      "\n",
      "V103: 928\n",
      "[ 0. 24.  1.  2.  4.  5.  3.  7. 10. 25. 26. 27. 28. 29. 30. 31. 32. 33.\n",
      "  6.  8.]\n",
      "\n",
      "\n",
      "V104: 16\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. nan]\n",
      "\n",
      "\n",
      "V105: 100\n",
      "[ 0.  1.  2.  4.  3. 11.  6.  5. 12.  7.  8.  9. 15. 10. 16. 13. 17. 14.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V106: 56\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V107: 2\n",
      "[ 1.  0. nan]\n",
      "\n",
      "\n",
      "V108: 8\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  0. nan]\n",
      "\n",
      "\n",
      "V109: 8\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  0. nan]\n",
      "\n",
      "\n",
      "V110: 8\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  0. nan]\n",
      "\n",
      "\n",
      "V111: 10\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9.  0. nan]\n",
      "\n",
      "\n",
      "V112: 10\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9.  0. nan]\n",
      "\n",
      "\n",
      "V113: 10\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9.  0. nan]\n",
      "\n",
      "\n",
      "V114: 7\n",
      "[ 1.  2.  3.  4.  5.  6.  0. nan]\n",
      "\n",
      "\n",
      "V115: 7\n",
      "[ 1.  2.  3.  4.  5.  6.  0. nan]\n",
      "\n",
      "\n",
      "V116: 7\n",
      "[ 1.  2.  3.  4.  5.  6.  0. nan]\n",
      "\n",
      "\n",
      "V117: 4\n",
      "[ 1.  2.  3.  0. nan]\n",
      "\n",
      "\n",
      "V118: 4\n",
      "[ 1.  2.  3.  0. nan]\n",
      "\n",
      "\n",
      "V119: 4\n",
      "[ 1.  2.  3.  0. nan]\n",
      "\n",
      "\n",
      "V120: 4\n",
      "[ 1.  2.  3.  0. nan]\n",
      "\n",
      "\n",
      "V121: 4\n",
      "[ 1.  2.  3.  0. nan]\n",
      "\n",
      "\n",
      "V122: 4\n",
      "[ 1.  2.  3.  0. nan]\n",
      "\n",
      "\n",
      "V123: 14\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.  0. nan]\n",
      "\n",
      "\n",
      "V124: 14\n",
      "[ 1.  4.  2.  3.  5.  6.  7.  9.  8. 10. 11. 12. 13.  0. nan]\n",
      "\n",
      "\n",
      "V125: 14\n",
      "[ 1.  3.  2.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.  0. nan]\n",
      "\n",
      "\n",
      "V126: 10299\n",
      "[   0.           50.          209.94999695   29.          774.\n",
      "  200.           58.95000076  530.         1054.           77.\n",
      "  780.          100.          280.          107.94999695   87.94999695\n",
      " 2594.94995117  107.           49.          325.           39.        ]\n",
      "\n",
      "\n",
      "V127: 24414\n",
      "[ 117.            0.         1758.           60.          100.\n",
      "  517.5         170.91999817 1131.69995117   29.         9311.5\n",
      "  145.          774.           49.         9511.5         326.\n",
      "  421.8999939   527.           58.95000076  140.         1568.        ]\n",
      "\n",
      "\n",
      "V128: 14507\n",
      "[   0.          925.          102.5          27.96999931  417.8999939\n",
      "   29.         2507.5          25.          774.           49.\n",
      " 2707.5         527.           58.95000076  655.         1225.\n",
      "   40.           77.          905.          480.          100.        ]\n",
      "\n",
      "\n",
      "V129: 1968\n",
      "[   0.          209.94999695   29.           58.95000076 1054.\n",
      "  280.           87.94999695 2594.94995117  107.          325.\n",
      "   34.5          26.5          83.5         107.94999695   30.95000076\n",
      "   35.         3162.94995117   31.95000076  311.95001221   50.        ]\n",
      "\n",
      "\n",
      "V130: 12332\n",
      "[   0.          354.           60.          100.          425.\n",
      "  170.91999817  605.84997559   29.         2956.          145.\n",
      "   49.          150.          210.94999695  527.           58.95000076\n",
      "  140.          621.         1896.          750.          375.8500061 ]\n",
      "\n",
      "\n",
      "V131: 4444\n",
      "[   0.          135.           34.           27.96999931  209.94999695\n",
      "   29.         1035.           25.           49.          527.\n",
      "   58.95000076  125.         1225.           40.          480.\n",
      "  280.           74.73999786   87.94999695   47.95000076 2594.94995117]\n",
      "\n",
      "\n",
      "V132: 6560\n",
      "[  0.          50.         200.         530.          77.\n",
      " 780.         100.          20.         321.          37.09790039\n",
      "  74.19580078  46.          25.95000076 356.          68.94999695\n",
      " 137.8999939   98.          25.          49.          59.        ]\n",
      "\n",
      "\n",
      "V133: 9949\n",
      "[ 117.            0.         1404.           68.5         417.8999939\n",
      " 6355.5        6555.5         176.          947.           77.\n",
      " 1197.          335.          791.5         100.           20.\n",
      "  697.          200.94999695  508.          321.           50.        ]\n",
      "\n",
      "\n",
      "V134: 8178\n",
      "[   0.          790.           68.5         207.94999695 1472.5\n",
      " 1672.5         530.           77.          780.          100.\n",
      "   20.          508.          321.           37.09790039   74.19580078\n",
      "   46.           50.           25.95000076  425.          165.8999939 ]\n",
      "\n",
      "\n",
      "V135: 3724\n",
      "[  0.         774.          50.         107.94999695 200.\n",
      "  39.          99.          59.         100.         300.\n",
      " 500.         160.5        150.          30.          60.\n",
      "  65.          10.          42.95000076 450.          44.95000076]\n",
      "\n",
      "\n",
      "V136: 4852\n",
      "[  0.          24.         107.94999695 774.         210.94999695\n",
      "  50.         200.          39.          99.          59.\n",
      " 100.         425.         300.          58.95000076 127.94999695\n",
      " 306.         108.5        500.         160.5        839.95001221]\n",
      "\n",
      "\n",
      "V137: 4252\n",
      "[  0.         774.          50.         107.94999695 200.\n",
      "  39.          99.          59.         100.         140.\n",
      " 300.          49.         500.         160.5        839.95001221\n",
      " 150.          30.          60.          65.          10.        ]\n",
      "\n",
      "\n",
      "V138: 23\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V139: 34\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V140: 34\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V141: 6\n",
      "[nan  0.  1.  2.  3.  4.  5.]\n",
      "\n",
      "\n",
      "V142: 10\n",
      "[nan  0.  1.  3.  4.  2.  5.  6.  7.  8.  9.]\n",
      "\n",
      "\n",
      "V143: 870\n",
      "[nan  6.  0.  5.  1.  7. 10. 11.  2.  3. 12.  4. 13. 14. 15.  8.  9. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V144: 63\n",
      "[nan 18.  0. 17.  1. 19.  2.  3. 20. 21. 22.  4. 23.  5.  6. 24. 16. 15.\n",
      " 14. 13.]\n",
      "\n",
      "\n",
      "V145: 260\n",
      "[ nan 140.   0. 141.   1. 142. 144.   8.   2.   3. 145. 146. 147. 148.\n",
      " 149.   4. 150.   5.   6. 143.]\n",
      "\n",
      "\n",
      "V146: 25\n",
      "[nan  0.  1.  2.  3.  7.  4.  5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V147: 27\n",
      "[nan  0.  1.  2.  3.  7.  4.  5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V148: 21\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V149: 21\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V150: 1996\n",
      "[      nan 1.803e+03 1.804e+03 1.805e+03 1.806e+03 1.000e+00 1.807e+03\n",
      " 2.000e+00 1.808e+03 1.809e+03 1.810e+03 1.812e+03 1.813e+03 1.814e+03\n",
      " 1.815e+03 1.816e+03 1.817e+03 1.818e+03 1.819e+03 1.820e+03]\n",
      "\n",
      "\n",
      "V151: 56\n",
      "[nan 49.  1.  4. 50. 51.  2. 52. 53. 54. 48. 47. 46. 45. 44. 43. 42.  3.\n",
      " 55. 56.]\n",
      "\n",
      "\n",
      "V152: 39\n",
      "[nan 64.  1.  4.  2.  7.  8.  3. 65. 66. 67. 68.  5.  6. 69. 63. 62. 61.\n",
      " 60. 59.]\n",
      "\n",
      "\n",
      "V153: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  0.  1.  6.  2.  3.  4.  5.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V154: 19\n",
      "[nan  0.  1.  7.  2.  8.  3.  4.  5.  6.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V155: 25\n",
      "[nan  0.  1.  2.  7.  3.  4.  5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V156: 25\n",
      "[nan  0.  1.  2.  8.  9.  3.  4.  5.  6.  7. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V157: 25\n",
      "[nan  0.  1.  2.  7.  3.  4.  5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V158: 25\n",
      "[nan  0.  1.  2.  8.  3.  9.  4.  5.  6.  7. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V159: 6663\n",
      "[           nan 15557.99023438 15607.99023438 15622.99023438\n",
      " 15652.99023438 15672.99023438     0.         15457.99023438\n",
      " 15382.99023438 15582.99023438 15632.99023438 15657.99023438\n",
      " 15732.99023438 15782.99023438 15762.99023438 15862.99023438\n",
      "    30.         16062.99023438 16077.99023438 16102.99023438]\n",
      "\n",
      "\n",
      "V160: 9621\n",
      "[           nan 1.69690797e+05 1.69740797e+05 1.69755797e+05\n",
      " 1.69785797e+05 1.69885797e+05 1.45000000e+02 1.69970797e+05\n",
      " 1.70020797e+05 1.20000000e+02 1.70320797e+05 0.00000000e+00\n",
      " 1.70420797e+05 1.70445797e+05 1.70545797e+05 1.70595797e+05\n",
      " 1.70695797e+05 1.70725797e+05 1.70825797e+05 2.77000000e+02]\n",
      "\n",
      "\n",
      "V161: 79\n",
      "[ nan   0. 500.  30.  50.  20. 100. 150. 200.   5.  25.  40. 450.  15.\n",
      " 270.  75.  35.  18. 250.  45.]\n",
      "\n",
      "\n",
      "V162: 185\n",
      "[ nan   0. 500.  70.  50. 130. 100. 150. 200.  20.   5. 155.  25.  40.\n",
      " 450.  15.  30. 110.  95. 115.]\n",
      "\n",
      "\n",
      "V163: 106\n",
      "[ nan   0. 500.  70.  50. 100. 150. 200.  20.   5.  25.  40. 450.  15.\n",
      "  30.  95. 470.  75. 120.  35.]\n",
      "\n",
      "\n",
      "V164: 1978\n",
      "[  nan  515.    0.  475.  575.   50.  250.  600.  750.   10.  795.   45.\n",
      "  100.  150.  870.  200.  945. 1020. 1070. 1045.]\n",
      "\n",
      "\n",
      "V165: 2547\n",
      "[  nan 5155.    0. 5255.   50.  250. 5280. 5430.   10. 5475. 5165.   45.\n",
      "  100.  150. 5240.  200. 5315. 5390. 5440.  700.]\n",
      "\n",
      "\n",
      "V166: 987\n",
      "[  nan 2840.    0. 2740. 2790. 2490.  200. 2540. 2610. 2560.  100.  300.\n",
      "  500.  475. 2760. 2910.  150.   30.   60.   90.]\n",
      "\n",
      "\n",
      "V167: 873\n",
      "[nan  0.  3.  4.  1.  5.  2.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V168: 965\n",
      "[nan  0.  3.  1.  4.  2.  5.  7.  8. 10.  6. 47. 38. 48. 41.  9. 11. 12.\n",
      " 13. 14.]\n",
      "\n",
      "\n",
      "V169: 20\n",
      "[nan  0.  3.  4.  5.  1.  2.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V170: 49\n",
      "[nan  1.  4.  5.  2.  6.  0.  3.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V171: 62\n",
      "[nan  1.  4.  5.  2.  6.  0.  3.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18.  7.]\n",
      "\n",
      "\n",
      "V172: 32\n",
      "[nan  0.  2.  3.  1.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V173: 8\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.]\n",
      "\n",
      "\n",
      "V174: 9\n",
      "[nan  0.  2.  1.  3.  4.  5.  6.  7.  8.]\n",
      "\n",
      "\n",
      "V175: 15\n",
      "[nan  0.  2.  1.  3.  4.  8.  5.  6.  7.  9. 10. 11. 12. 13. 14.]\n",
      "\n",
      "\n",
      "V176: 49\n",
      "[nan  1.  4.  5.  6.  2.  3.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V177: 862\n",
      "[nan  0.  1.  2.  3.  4.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.  5.  6.\n",
      " 20. 21.]\n",
      "\n",
      "\n",
      "V178: 1236\n",
      "[nan  0.  1.  2.  6.  7.  8.  3.  4. 65. 18. 13. 20.  9. 10. 11. 12. 14.\n",
      " 15. 16.]\n",
      "\n",
      "\n",
      "V179: 921\n",
      "[nan  0.  1.  2.  7.  3.  4. 26. 17. 19.  8.  9. 10. 11. 12. 13. 14. 15.\n",
      " 16. 27.]\n",
      "\n",
      "\n",
      "V180: 84\n",
      "[nan  0.  1.  2.  8.  3.  5.  4.  6. 22.  7. 23. 15. 18. 24. 16. 11.  9.\n",
      " 10. 17.]\n",
      "\n",
      "\n",
      "V181: 25\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V182: 84\n",
      "[nan  0.  1.  2.  4.  3.  5.  8.  6. 14.  7. 15. 11. 18. 10. 16. 17.  9.\n",
      " 19. 12.]\n",
      "\n",
      "\n",
      "V183: 42\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 11. 13. 14. 10. 12. 15. 16.\n",
      " 17. 22.]\n",
      "\n",
      "\n",
      "V184: 17\n",
      "[nan  0.  1.  2.  3.  4.  7.  5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "\n",
      "\n",
      "V185: 32\n",
      "[nan  0.  1.  2.  3.  5.  4.  7.  8.  6.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V186: 39\n",
      "[nan  1.  2.  4.  5.  3.  6.  7.  8.  9. 10. 11. 12. 13. 14. 16. 17. 18.\n",
      " 19. 20.]\n",
      "\n",
      "\n",
      "V187: 215\n",
      "[nan  1.  2.  4.  3. 85. 28. 31. 30.  5. 84. 29.  6. 82. 83.  7. 32. 33.\n",
      "  8.  9.]\n",
      "\n",
      "\n",
      "V188: 31\n",
      "[nan  1.  2.  0.  4.  3.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V189: 31\n",
      "[nan  1.  2.  0.  4.  3.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V190: 43\n",
      "[nan  1.  2.  4.  3.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 17. 18.\n",
      " 19. 20.]\n",
      "\n",
      "\n",
      "V191: 22\n",
      "[nan  1.  4.  2.  5.  3.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V192: 45\n",
      "[nan  1.  4.  2. 30. 16. 18.  7. 17.  5.  8.  3. 29. 15.  6. 19. 20. 21.\n",
      " 23. 24.]\n",
      "\n",
      "\n",
      "V193: 38\n",
      "[nan  1.  4.  2. 18. 14.  3.  7. 15.  8.  5. 16. 17.  9. 10. 11. 12. 13.\n",
      " 19. 20.]\n",
      "\n",
      "\n",
      "V194: 8\n",
      "[nan  1.  0.  4.  2.  6.  3.  5.  7.]\n",
      "\n",
      "\n",
      "V195: 17\n",
      "[nan  1.  0.  4.  2.  7.  8.  3.  5.  6.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "\n",
      "\n",
      "V196: 39\n",
      "[nan  1.  4.  2.  5.  3.  6.  7.  8.  9. 10. 11. 12. 13. 14. 16. 17. 18.\n",
      " 19. 20.]\n",
      "\n",
      "\n",
      "V197: 15\n",
      "[nan  1.  0.  4.  2.  7.  3.  5.  6.  8. 11.  9. 10. 12. 13. 14.]\n",
      "\n",
      "\n",
      "V198: 22\n",
      "[nan  1.  0.  4.  2.  3.  8.  9.  5.  6.  7. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V199: 46\n",
      "[nan  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 17. 18.\n",
      " 19. 20.]\n",
      "\n",
      "\n",
      "V200: 46\n",
      "[nan  1.  2.  0.  3.  4.  7.  5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V201: 56\n",
      "[nan  1.  2.  0.  3.  4.  8.  9.  5.  6.  7. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V202: 10970\n",
      "[          nan    0.          166.21539307  242.10290527  100.\n",
      "   50.          317.99038696  200.           30.           37.09790039\n",
      "   74.19580078    8.6406002    57.27870178  300.          500.\n",
      "  725.         1000.           43.01900101   35.          150.        ]\n",
      "\n",
      "\n",
      "V203: 14951\n",
      "[         nan   0.         166.21539307 125.         242.10290527\n",
      " 140.         100.          50.         317.99038696 200.\n",
      " 314.          25.01390076  37.09790039  74.19580078   8.6406002\n",
      "  57.27870178  16.85720062 300.         500.          20.        ]\n",
      "\n",
      "\n",
      "V204: 12858\n",
      "[          nan    0.          166.21539307   25.          242.10290527\n",
      "   40.          100.           50.          317.99038696  200.\n",
      "   75.           37.09790039   74.19580078    8.6406002    57.27870178\n",
      "  300.          500.          725.         1000.           43.01900101]\n",
      "\n",
      "\n",
      "V205: 2240\n",
      "[          nan    0.           90.32790375  166.21539307   30.\n",
      "    8.6406002   500.           35.            1.89579999    6.\n",
      "    7.29540014  127.78829956   12.32569981   51.35699844   16.01180077\n",
      "   18.18639946  150.          650.         1000.          200.        ]\n",
      "\n",
      "\n",
      "V206: 1780\n",
      "[         nan   0.          31.84129906 107.72879791   8.6406002\n",
      " 500.          35.           1.89579999   6.           7.29540014\n",
      " 127.78829956  12.32569981  51.35699844  16.01180077 150.\n",
      " 120.         100.           5.          38.1853981   25.        ]\n",
      "\n",
      "\n",
      "V207: 3246\n",
      "[         nan   0.          90.32790375  25.          40.\n",
      " 166.21539307  30.           8.6406002  500.          35.\n",
      "  22.           1.89579999   6.           7.29540014  18.4885006\n",
      " 127.78829956  12.32569981  51.35699844  19.33440018  16.01180077]\n",
      "\n",
      "\n",
      "V208: 2552\n",
      "[         nan   0.          90.32790375  30.          50.\n",
      " 125.         166.21539307  25.01390076   8.6406002   16.85720062\n",
      "  20.         500.          35.           6.         127.78829956\n",
      "  12.32569981  51.35699844  19.33440018  16.01180077  18.18639946]\n",
      "\n",
      "\n",
      "V209: 3451\n",
      "[         nan   0.          90.32790375 125.         140.\n",
      " 166.21539307  25.01390076   8.6406002   16.85720062  20.\n",
      " 500.          35.         130.           6.         127.78829956\n",
      "  12.32569981  19.1807003   51.35699844  19.33440018  16.01180077]\n",
      "\n",
      "\n",
      "V210: 2836\n",
      "[         nan   0.          90.32790375  30.          50.\n",
      " 125.         166.21539307  25.01390076   8.6406002   16.85720062\n",
      "  20.         500.          35.           6.         127.78829956\n",
      "  12.32569981  51.35699844  19.33440018  16.01180077  18.18639946]\n",
      "\n",
      "\n",
      "V211: 7624\n",
      "[          nan    0.          100.           37.09790039   74.19580078\n",
      "   48.63809967   50.          250.           25.            5.39960003\n",
      "   85.19219971  170.38439941  255.57659912   10.           45.\n",
      "  340.76879883   90.87169647 1100.          150.           75.        ]\n",
      "\n",
      "\n",
      "V212: 8868\n",
      "[         nan   0.         100.          37.09790039  74.19580078\n",
      "  48.63809967  50.         250.          25.          15.07509995\n",
      " 347.65640259  20.47470093 141.7454071   85.19219971 170.38439941\n",
      " 255.57659912  10.          45.         340.76879883  32.3246994 ]\n",
      "\n",
      "\n",
      "V213: 8317\n",
      "[         nan   0.         100.          37.09790039  74.19580078\n",
      "  48.63809967  50.         250.          25.         347.65640259\n",
      "   5.39960003  18.48839951  85.19219971 170.38439941 255.57659912\n",
      "  10.          45.         340.76879883 165.06739807  90.87169647]\n",
      "\n",
      "\n",
      "V214: 2282\n",
      "[         nan   0.          75.88749695 151.7749939   50.\n",
      " 200.         100.         300.         500.         475.\n",
      "  43.01900101 150.          30.          60.          71.47689819\n",
      "  90.          65.          10.          16.01180077  32.02360153]\n",
      "\n",
      "\n",
      "V215: 2747\n",
      "[         nan   0.          75.88749695 151.7749939   50.\n",
      " 200.          65.         100.         300.         500.\n",
      " 475.          43.01900101   8.         150.          30.\n",
      "  60.          71.47689819  90.          10.          16.01180077]\n",
      "\n",
      "\n",
      "V216: 2532\n",
      "[         nan   0.          75.88749695 151.7749939   50.\n",
      " 200.          45.         100.         300.         500.\n",
      " 475.          43.01900101 150.          30.          60.\n",
      "  71.47689819  90.          65.          10.          16.01180077]\n",
      "\n",
      "\n",
      "V217: 304\n",
      "[nan  0.  3.  4.  1.  5.  2.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V218: 401\n",
      "[ nan   0.   3.   4.   2.   1.   5. 174.   9.   6.  10. 175.  31. 176.\n",
      " 177.   7.   8. 178.  11.  12.]\n",
      "\n",
      "\n",
      "V219: 379\n",
      "[nan  0.  3.  4.  1.  5.  2. 73. 74. 10. 75. 76.  8.  7.  9. 11. 12. 13.\n",
      " 14. 15.]\n",
      "\n",
      "\n",
      "V220: 26\n",
      "[nan  0.  3.  4.  5.  1.  2.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V221: 77\n",
      "[nan  1.  4.  5.  0.  2.  6.  3.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18.  7.]\n",
      "\n",
      "\n",
      "V222: 76\n",
      "[nan  1.  4.  5.  0.  2.  6.  3.  9.  8. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18.  7.]\n",
      "\n",
      "\n",
      "V223: 17\n",
      "[nan  0.  2.  3.  1.  6.  7.  8.  9. 10. 11. 12.  4.  5. 13. 14. 15. 16.]\n",
      "\n",
      "\n",
      "V224: 79\n",
      "[ nan   0.   2.   3.   1. 107.   5. 108.  17. 109. 110.   7. 111. 112.\n",
      " 113.   4.  10. 114. 115.   6.]\n",
      "\n",
      "\n",
      "V225: 35\n",
      "[nan  0.  2.  3.  1. 42. 43. 10. 44. 45.  4. 46. 47.  5. 48. 49. 50.  9.\n",
      " 51. 32.]\n",
      "\n",
      "\n",
      "V226: 81\n",
      "[ nan   0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.\n",
      " 121. 242.  16.  13.  14.  15.]\n",
      "\n",
      "\n",
      "V227: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan   0.   2.   3.   1.   4.   6.  13.  23.   8.  61.  32.  78.   9.\n",
      "  17.  36.  84. 130. 213.  42.]\n",
      "\n",
      "\n",
      "V228: 55\n",
      "[nan  1.  4.  5.  6.  2.  3.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V229: 91\n",
      "[ nan   1.   4.   5.   2.   6.   3. 140.   9. 141. 142. 143.   8. 144.\n",
      "   7. 145. 146.  10. 147. 148.]\n",
      "\n",
      "\n",
      "V230: 66\n",
      "[nan  1.  4.  5.  6.  2.  3. 59. 60. 61. 62.  8. 63.  9. 10. 64. 65.  7.\n",
      " 35. 36.]\n",
      "\n",
      "\n",
      "V231: 294\n",
      "[nan  0.  1.  2.  3.  4.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.  5.  6.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V232: 338\n",
      "[nan  0.  2.  1.  3. 33.  7.  8.  4.  9. 10. 11. 12. 13. 14. 15. 16.  5.\n",
      "  6. 32.]\n",
      "\n",
      "\n",
      "V233: 333\n",
      "[nan  0.  1.  2.  3. 18.  4.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.  5.\n",
      "  6. 17.]\n",
      "\n",
      "\n",
      "V234: 122\n",
      "[nan  0.  1.  2. 35.  3.  4.  5. 34. 22. 49. 50.  7. 51. 18.  8. 54.  6.\n",
      " 55. 36.]\n",
      "\n",
      "\n",
      "V235: 24\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V236: 46\n",
      "[nan  0.  1.  2. 29.  3.  4.  5. 11.  7. 18.  8. 28. 30. 26. 27. 31.  9.\n",
      "  6. 19.]\n",
      "\n",
      "\n",
      "V237: 40\n",
      "[nan  0.  1.  2. 13.  3.  4.  7.  5.  8. 12. 10.  9.  6. 11. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V238: 24\n",
      "[nan  0.  1.  2.  3.  4.  7.  5.  6.  8. 11.  9. 14. 10. 23. 16. 12. 13.\n",
      " 15. 20.]\n",
      "\n",
      "\n",
      "V239: 24\n",
      "[nan  0.  1.  2.  3.  4.  7.  5.  8.  6. 11.  9. 14. 10. 23. 16. 12. 13.\n",
      " 15. 20.]\n",
      "\n",
      "\n",
      "V240: 6\n",
      "[nan  1.  2.  5.  6.  7.  0.]\n",
      "\n",
      "\n",
      "V241: 5\n",
      "[nan  1.  2.  4.  5.  0.]\n",
      "\n",
      "\n",
      "V242: 21\n",
      "[nan  1.  2.  7.  4.  8.  9. 10.  3. 11. 12.  6.  5. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V243: 43\n",
      "[nan  1.  2. 49.  4.  3. 50. 51.  5.  6. 52. 53. 47. 48.  7.  8.  9. 33.\n",
      " 34. 40.]\n",
      "\n",
      "\n",
      "V244: 23\n",
      "[nan  1.  2.  7.  4.  8.  9. 10. 11. 12. 13.  3.  5.  6. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V245: 58\n",
      "[ nan   1.   2.   0.   3.   7.   4.  13.   5.   6.  24.   8.   9.  59.\n",
      "  33.  80.  12. 102.  10.  11.]\n",
      "\n",
      "\n",
      "V246: 46\n",
      "[nan  1.  2.  7.  4.  3.  8.  9. 10. 11. 12. 13.  5.  6. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V247: 19\n",
      "[nan  1.  6.  4.  2.  7.  8.  9.  5.  3. 10. 11. 12.  0. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V248: 23\n",
      "[nan  1.  2. 35.  4.  3.  7.  5.  6.  8. 36. 33. 34. 13.  9. 10.  0. 11.\n",
      " 12. 14.]\n",
      "\n",
      "\n",
      "V249: 23\n",
      "[nan  1. 21.  4.  3.  2.  7.  5.  8. 22. 20. 19.  6. 16. 17. 18.  0.  9.\n",
      " 10. 11.]\n",
      "\n",
      "\n",
      "V250: 19\n",
      "[nan  1.  0.  2.  6.  3.  4.  8.  5.  7. 10. 13. 11. 16. 12. 17.  9. 14.\n",
      " 15. 18.]\n",
      "\n",
      "\n",
      "V251: 19\n",
      "[nan  1.  0.  2.  7.  8.  3.  4.  6.  5. 11. 10. 13. 16. 12. 17.  9. 14.\n",
      " 15. 18.]\n",
      "\n",
      "\n",
      "V252: 25\n",
      "[nan  1.  7.  4.  2.  8.  9. 10. 11. 12. 13.  3.  5.  6. 14. 15. 16. 17.\n",
      " 18.  0.]\n",
      "\n",
      "\n",
      "V253: 66\n",
      "[ nan   1.   2. 131.   4.   3.   5. 132. 133. 134.   8. 135.   7. 136.\n",
      " 137.   9. 138. 139.   6.  61.]\n",
      "\n",
      "\n",
      "V254: 45\n",
      "[nan  1.  2. 54.  4.  3. 55. 56. 57.  8.  5.  6. 58.  9. 59. 60. 26. 27.\n",
      " 45. 43.]\n",
      "\n",
      "\n",
      "V255: 46\n",
      "[nan  1.  0.  2.  7.  3.  4. 12.  5.  6. 19.  9. 40. 23. 43.  8. 11. 22.\n",
      " 46. 53.]\n",
      "\n",
      "\n",
      "V256: 48\n",
      "[nan  1.  0.  2.  8.  9.  3.  4.  7. 12.  5.  6. 19. 40. 23. 43. 11. 22.\n",
      " 46. 61.]\n",
      "\n",
      "\n",
      "V257: 49\n",
      "[nan  1.  2.  3.  7.  4.  8.  9. 10. 11. 12. 13.  5.  6. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V258: 67\n",
      "[nan  1.  2.  3. 60.  4. 61. 62. 63.  8.  5.  6. 64.  9. 65. 66.  7. 35.\n",
      " 36. 46.]\n",
      "\n",
      "\n",
      "V259: 68\n",
      "[nan  1.  2.  0.  3.  5.  7.  4. 13.  6. 24.  8.  9. 11. 65. 34. 84. 10.\n",
      " 12. 33.]\n",
      "\n",
      "\n",
      "V260: 9\n",
      "[nan  1.  0.  2.  4.  3.  5.  6.  7.  8.]\n",
      "\n",
      "\n",
      "V261: 41\n",
      "[nan  1.  0.  2.  3. 37.  4.  5. 38. 39. 40. 36.  6. 35. 13. 41.  7. 43.\n",
      " 42. 44.]\n",
      "\n",
      "\n",
      "V262: 21\n",
      "[nan  1.  0. 17.  4.  2. 18. 19. 20.  5.  3. 16. 15. 14. 13. 11. 12.  7.\n",
      "  6.  8.]\n",
      "\n",
      "\n",
      "V263: 10422\n",
      "[          nan    0.          166.21539307  242.10290527  100.\n",
      "   50.          317.99038696  200.           37.09790039   74.19580078\n",
      "    8.6406002    57.27870178  750.          300.          500.\n",
      "  725.         1000.           43.01900101   35.           32.3246994 ]\n",
      "\n",
      "\n",
      "V264: 13358\n",
      "[           nan 0.00000000e+00 1.66215393e+02 2.42102905e+02\n",
      " 5.00000000e+01 1.00000000e+02 3.17990387e+02 2.00000000e+02\n",
      " 7.00871964e+01 3.70979004e+01 7.41958008e+01 7.87277985e+01\n",
      " 1.27365898e+02 1.77031002e+01 1.62288605e+02 6.07750000e+04\n",
      " 1.68572006e+01 3.00000000e+02 5.00000000e+02 7.25000000e+02]\n",
      "\n",
      "\n",
      "V265: 11757\n",
      "[           nan 0.00000000e+00 1.66215393e+02 2.42102905e+02\n",
      " 1.00000000e+02 5.00000000e+01 3.17990387e+02 2.00000000e+02\n",
      " 7.00871964e+01 3.70979004e+01 7.41958008e+01 7.87277985e+01\n",
      " 1.27365898e+02 5.46195984e+01 3.93250000e+04 3.00000000e+02\n",
      " 5.00000000e+02 7.25000000e+02 1.00000000e+03 4.30190010e+01]\n",
      "\n",
      "\n",
      "V266: 2178\n",
      "[          nan    0.           90.32790375  166.21539307    8.6406002\n",
      "  750.          500.           35.            7.94999981    1.89579999\n",
      "    6.            7.29540014  127.78829956   12.32569981   51.35699844\n",
      "   16.01180077  950.           30.         1050.          150.        ]\n",
      "\n",
      "\n",
      "V267: 3616\n",
      "[           nan 0.00000000e+00 9.03279037e+01 1.66215393e+02\n",
      " 8.64060020e+00 1.77031002e+01 1.07668999e+02 2.01000000e+04\n",
      " 1.68572006e+01 5.00000000e+02 1.71592999e+01 3.50000000e+01\n",
      " 4.00000000e+01 7.00000000e+01 3.02450008e+01 1.85499992e+01\n",
      " 2.93640995e+01 1.89579999e+00 6.00000000e+00 7.29540014e+00]\n",
      "\n",
      "\n",
      "V268: 2756\n",
      "[           nan 0.00000000e+00 9.03279037e+01 1.66215393e+02\n",
      " 8.64060020e+00 1.08750000e+04 5.00000000e+02 3.50000000e+01\n",
      " 7.94999981e+00 1.89579999e+00 6.00000000e+00 7.29540014e+00\n",
      " 1.27788300e+02 1.23256998e+01 1.50000000e+01 5.13569984e+01\n",
      " 1.60118008e+01 1.11750000e+04 4.00000000e+02 1.12750000e+04]\n",
      "\n",
      "\n",
      "V269: 151\n",
      "[  nan    0.  750.  500.    6.  950.   30. 1050.  150. 1200.    5. 1300.\n",
      " 1700. 1900.  100. 2100. 2200. 2250. 2300.   25.]\n",
      "\n",
      "\n",
      "V270: 2340\n",
      "[         nan   0.          90.32790375 166.21539307  16.85720062\n",
      " 500.          17.15929985  30.           1.89579999   6.\n",
      "   7.29540014 127.78829956  15.          51.35699844  16.01180077\n",
      "  20.          10.         120.          50.         600.        ]\n",
      "\n",
      "\n",
      "V271: 2787\n",
      "[         nan   0.          90.32790375 166.21539307   8.6406002\n",
      "  16.85720062 500.          17.15929985  70.           1.89579999\n",
      "   6.           7.29540014 127.78829956  15.          51.35699844\n",
      "  16.01180077 130.          65.         120.         250.        ]\n",
      "\n",
      "\n",
      "V272: 2507\n",
      "[         nan   0.          90.32790375 166.21539307   8.6406002\n",
      "  16.85720062 500.          17.15929985  70.           1.89579999\n",
      "   6.           7.29540014 127.78829956  15.          51.35699844\n",
      "  16.01180077 100.          30.         120.         150.        ]\n",
      "\n",
      "\n",
      "V273: 7177\n",
      "[         nan   0.         100.          37.09790039  74.19580078\n",
      "  48.63809967  50.         250.          25.           5.39960003\n",
      "  85.19219971 170.38439941 255.57659912  10.          45.\n",
      " 340.76879883 150.          75.         200.         225.        ]\n",
      "\n",
      "\n",
      "V274: 8315\n",
      "[           nan 0.00000000e+00 5.00000000e+01 1.00000000e+02\n",
      " 7.00871964e+01 3.70979004e+01 7.41958008e+01 1.18725304e+02\n",
      " 2.73097992e+01 2.58000000e+04 2.50000000e+02 5.65531998e+01\n",
      " 2.55576706e+02 2.50000000e+01 2.26816696e+02 2.14189896e+02\n",
      " 5.39960003e+00 1.43943802e+02 3.69770012e+01 8.51921997e+01]\n",
      "\n",
      "\n",
      "V275: 7776\n",
      "[           nan 0.00000000e+00 1.00000000e+02 7.00871964e+01\n",
      " 3.70979004e+01 7.41958008e+01 1.18725304e+02 2.73097992e+01\n",
      " 5.00000000e+01 2.08500000e+04 2.50000000e+02 2.50000000e+01\n",
      " 1.51895905e+02 5.39960003e+00 8.51921997e+01 1.70384399e+02\n",
      " 2.55576599e+02 1.00000000e+01 4.50000000e+01 3.40768799e+02]\n",
      "\n",
      "\n",
      "V276: 2263\n",
      "[         nan   0.          75.88749695 151.7749939   50.\n",
      " 200.         100.         300.         500.         475.\n",
      "  43.01900101  32.3246994  150.          30.          60.\n",
      "  71.47689819  90.          65.          10.          16.01180077]\n",
      "\n",
      "\n",
      "V277: 2540\n",
      "[           nan     0.            75.88749695   151.7749939\n",
      "    50.           200.            27.30979919 11650.\n",
      "   100.           300.           500.           475.\n",
      "    30.75379944    43.01900101    13.6548996     32.3246994\n",
      "   150.           101.26390076    30.            60.        ]\n",
      "\n",
      "\n",
      "V278: 2398\n",
      "[          nan    0.           75.88749695  151.7749939    50.\n",
      "  200.           27.30979919 7600.          100.          300.\n",
      "  500.          475.           43.01900101   32.3246994   150.\n",
      "  101.26390076   30.           60.           71.47689819   90.        ]\n",
      "\n",
      "\n",
      "V279: 881\n",
      "[ 0.  1.  3.  2.  4.  5.  8.  9.  6.  7. 10. 11. 12. 13. 32. 30. 14. 15.\n",
      " 16. 17.]\n",
      "\n",
      "\n",
      "V280: 975\n",
      "[ 0. 28.  3.  2.  1.  8.  9.  4.  5. 12. 13. 11. 29.  6. 31. 32.  7. 33.\n",
      " 30. 34.]\n",
      "\n",
      "\n",
      "V281: 23\n",
      "[ 0.  3.  1.  2.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V282: 33\n",
      "[ 1.  0.  4.  2.  3.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "\n",
      "\n",
      "V283: 62\n",
      "[ 1.  0.  4.  2.  3.  5.  6.  7.  8.  9. 10. 18. 11. 12. 13. 14. 68. 15.\n",
      " 16. 17.]\n",
      "\n",
      "\n",
      "V284: 13\n",
      "[ 0.  2.  1.  3.  4.  5. nan  6.  7.  8.  9. 10. 11. 12.]\n",
      "\n",
      "\n",
      "V285: 96\n",
      "[ 0. 10.  2.  1.  5.  4.  9.  6.  3.  7. 23.  8. 24. 12. 25. 11. 18. 15.\n",
      " 17. 19.]\n",
      "\n",
      "\n",
      "V286: 9\n",
      "[ 0.  1.  2.  3.  4. nan  5.  6.  7.  8.]\n",
      "\n",
      "\n",
      "V287: 32\n",
      "[ 0.  4.  2.  1.  3.  6. 10.  7.  8.  5.  9. 11. 12. 13. nan 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V288: 11\n",
      "[ 0.  2.  1.  3.  4.  5.  6.  7.  8. nan  9. 10.]\n",
      "\n",
      "\n",
      "V289: 13\n",
      "[ 0.  2.  1.  4.  3.  7.  5.  6.  8.  9. nan 10. 11. 12.]\n",
      "\n",
      "\n",
      "V290: 58\n",
      "[ 1.  4.  2.  3.  5.  6. 33. 31.  7.  8.  9. 16. 18. 19. 27. 29. nan 34.\n",
      " 21. 22.]\n",
      "\n",
      "\n",
      "V291: 219\n",
      "[  1.   4.   2.   3.   5.   6.   7.   8.   9.  10. 873. 874.  11.  12.\n",
      "  13.  14. 862. 854. 853.  22.]\n",
      "\n",
      "\n",
      "V292: 173\n",
      "[  1.   4.   2.   3.   5.   6.   9.  10. 178. 172.   7.   8.  11.  12.\n",
      "  13.  14. 177. 180. 179. 184.]\n",
      "\n",
      "\n",
      "V293: 870\n",
      "[ 0.  1.  2.  3.  4.  8.  9.  5.  6.  7. 10. 11. 12. 13. 30. 28. 14. 15.\n",
      " 16. 26.]\n",
      "\n",
      "\n",
      "V294: 1286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0. 38. 17. 18.  4.  5.  6.  2.  3. 10. 11.  7. 39. 13. 61.  8.  9.\n",
      " 62. 12.]\n",
      "\n",
      "\n",
      "V295: 928\n",
      "[ 0. 24.  1.  4.  5.  2.  3. 10. 11.  7. 25.  6. 26. 27.  8. 28. 29. 30.\n",
      " 31. 32.]\n",
      "\n",
      "\n",
      "V296: 94\n",
      "[ 0.  1.  3.  2.  6. 11.  4.  7.  5.  8.  9. 21. 51. 10. 12. 52. 54. 22.\n",
      " 13. 14.]\n",
      "\n",
      "\n",
      "V297: 13\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. nan 10. 11. 12.]\n",
      "\n",
      "\n",
      "V298: 94\n",
      "[ 0.  1.  2.  6.  3. 11.  4.  7.  5.  8.  9. 17. 39. 10. 12. 40. 18. 13.\n",
      " 14. 15.]\n",
      "\n",
      "\n",
      "V299: 50\n",
      "[ 0.  1.  2.  3.  4.  5.  7.  6.  8.  9. 13. 10. 11. 12. 14. 15. 16. 19.\n",
      " 17. nan]\n",
      "\n",
      "\n",
      "V300: 12\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. nan]\n",
      "\n",
      "\n",
      "V301: 14\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. nan 12. 13.]\n",
      "\n",
      "\n",
      "V302: 17\n",
      "[ 0.  1.  2.  3.  4.  5. nan  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "\n",
      "\n",
      "V303: 21\n",
      "[ 0.  1.  2.  7.  4.  3. 13.  5.  8.  6.  9. nan 17. 10. 11. 12. 15. 14.\n",
      " 16. 18.]\n",
      "\n",
      "\n",
      "V304: 17\n",
      "[ 0.  1.  2.  3.  7.  4.  5. nan  6.  8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "\n",
      "\n",
      "V305: 2\n",
      "[ 1.  2. nan]\n",
      "\n",
      "\n",
      "V306: 16210\n",
      "[   0.           50.          166.21539307   29.          774.\n",
      "  200.           58.95000076  530.         1054.          500.\n",
      "   77.          780.          100.           42.59609985  280.\n",
      "   54.37799835  107.94999695   75.88749695   66.15989685   89.9654007 ]\n",
      "\n",
      "\n",
      "V307: 37367\n",
      "[  117.             0.          1758.           166.21539307\n",
      "    60.           100.           663.5          170.91999817\n",
      "    29.          9969.5          145.           774.\n",
      "    48.95000076    49.         10169.5          103.94999695\n",
      "   421.8999939    527.           167.8999939    140.        ]\n",
      "\n",
      "\n",
      "V308: 23064\n",
      "[   0.          925.          166.21539307  102.5          27.96999931\n",
      "   29.         2507.5          25.          774.           49.\n",
      " 2707.5         527.           58.95000076  655.         1225.\n",
      " 1027.           77.          905.          480.          100.        ]\n",
      "\n",
      "\n",
      "V309: 4236\n",
      "[   0.           90.32790375   29.           58.95000076 1054.\n",
      "   42.59609985  280.           75.88749695   54.37799835   87.94999695\n",
      " 2594.94995117  107.          325.           30.           28.69949913\n",
      "    8.6406002    34.           34.5          26.5          83.5       ]\n",
      "\n",
      "\n",
      "V310: 19136\n",
      "[   0.          354.           90.32790375   60.          100.\n",
      "  425.          170.91999817   29.         2956.          145.\n",
      "   48.95000076   49.          103.94999695  210.94999695  527.\n",
      "  167.8999939   140.          350.         1896.            3.08139992]\n",
      "\n",
      "\n",
      "V311: 3098\n",
      "[0.00000000e+00 3.18412991e+01 2.90000000e+01 4.25960999e+01\n",
      " 7.58874969e+01 5.43779984e+01 8.79499969e+01 5.89500008e+01\n",
      " 2.59494995e+03 1.07000000e+02 2.86994991e+01 8.64060020e+00\n",
      " 3.40000000e+01 2.65000000e+01 1.07949997e+02 5.00000000e+02\n",
      " 3.09500008e+01 3.16294995e+03 3.11950012e+02 1.89579999e+00]\n",
      "\n",
      "\n",
      "V312: 8068\n",
      "[   0.          135.           90.32790375   34.           27.96999931\n",
      "   29.         1035.           25.           49.          527.\n",
      "   58.95000076  125.         1225.          480.           42.59609985\n",
      "  280.           75.88749695   74.73999786   54.37799835   87.94999695]\n",
      "\n",
      "\n",
      "V313: 5529\n",
      "[   0.           90.32790375   29.          226.           49.\n",
      "  210.94999695  527.          474.95001221  108.94999695    3.08139992\n",
      "   87.           59.           26.95000076   42.59609985  280.\n",
      "   58.95000076   75.88749695  312.67001343   54.37799835 2594.94995117]\n",
      "\n",
      "\n",
      "V314: 11377\n",
      "[   0.          495.           90.32790375   50.           93.\n",
      "  748.79998779   29.         2956.           49.          210.94999695\n",
      "  527.          474.95001221  167.8999939     6.16279984   87.\n",
      "   59.          226.           26.95000076   42.59609985   84.94999695]\n",
      "\n",
      "\n",
      "V315: 6973\n",
      "[  0.          90.32790375  29.         926.          49.\n",
      " 210.94999695 527.         474.95001221 108.94999695   3.08139992\n",
      "  87.          59.         226.          26.95000076  42.59609985\n",
      " 280.         107.90000153  75.88749695 435.77999878  54.37799835]\n",
      "\n",
      "\n",
      "V316: 9814\n",
      "[   0.           50.          200.          530.          500.\n",
      "   77.          780.          100.           23.80550003   20.\n",
      "  321.           48.63809967   46.          120.94999695   97.27619934\n",
      "  145.91430664  194.55239868 2057.94995117   25.95000076  356.        ]\n",
      "\n",
      "\n",
      "V317: 15184\n",
      "[ 117.            0.         1404.           68.5        7013.5\n",
      " 7213.5         801.          500.           77.         1051.\n",
      "  335.          791.5         100.           23.80550003   20.\n",
      "  697.          535.95001221  113.          321.           50.        ]\n",
      "\n",
      "\n",
      "V318: 12309\n",
      "[   0.          790.           68.5        1472.5        1672.5\n",
      "  530.          500.           77.          780.          100.\n",
      "   23.80550003   20.           64.          321.           48.63809967\n",
      "   46.           50.          120.94999695   97.27619934  145.91430664]\n",
      "\n",
      "\n",
      "V319: 4799\n",
      "[   0.           75.88749695  774.           50.          107.94999695\n",
      "  200.           99.           59.          100.          300.\n",
      "  500.          160.5         150.          117.90000153 3000.\n",
      "   30.           60.          113.94999695  650.           80.96279907]\n",
      "\n",
      "\n",
      "V320: 6439\n",
      "[  0.          75.88749695 170.         774.         210.94999695\n",
      "   5.07530022  50.         107.94999695 200.          57.\n",
      "  40.         139.          59.         100.          64.6493988\n",
      " 703.         300.          58.95000076 127.94999695 306.        ]\n",
      "\n",
      "\n",
      "V321: 5560\n",
      "[   0.           75.88749695  774.           50.          107.94999695\n",
      "  200.           40.          139.           59.          100.\n",
      "  140.          300.           49.          500.          160.5\n",
      "  839.95001221  150.          117.90000153 3000.           30.        ]\n",
      "\n",
      "\n",
      "V322: 881\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V323: 1411\n",
      "[nan  0.  6.  4.  1.  2.  3. 27. 10.  5. 25.  7. 18. 28.  8.  9. 11. 12.\n",
      " 13. 14.]\n",
      "\n",
      "\n",
      "V324: 976\n",
      "[nan  0.  1.  2.  3.  4.  5. 10.  6.  7.  8.  9. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V325: 13\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
      "\n",
      "\n",
      "V326: 45\n",
      "[nan  0.  6.  4.  1. 26.  3.  5. 25. 18. 27. 15.  2. 17.  8. 19. 10. 16.\n",
      " 28. 20.]\n",
      "\n",
      "\n",
      "V327: 19\n",
      "[nan  0.  1.  2. 10.  6.  3.  8.  7.  5.  4.  9. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V328: 16\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
      "\n",
      "\n",
      "V329: 100\n",
      "[nan  0.  1.  2.  3.  4.  5.  6. 13.  7. 14.  8. 12.  9. 10. 11. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V330: 56\n",
      "[nan  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.\n",
      " 17. 18.]\n",
      "\n",
      "\n",
      "V331: 1758\n",
      "[ nan   0. 100.  50. 200. 300. 500.  35. 150.  25.  30.   6.  60.  65.\n",
      "  10.  20.  45.  75. 125. 450.]\n",
      "\n",
      "\n",
      "V332: 2453\n",
      "[ nan   0. 145. 140. 125. 100.  50. 200.  30. 300. 500.  20.  35. 310.\n",
      " 150.  70.  25.   6.  10.  60.]\n",
      "\n",
      "\n",
      "V333: 1971\n",
      "[ nan   0.  25.  40. 100.  50. 200. 300. 500.  35.  22. 150.  30.   6.\n",
      "  60.  65.  10.  20.  45.  15.]\n",
      "\n",
      "\n",
      "V334: 143\n",
      "[ nan   0.  35.   6.  50.  30. 150.   5.   7. 100.  10.  25.  20. 125.\n",
      "  55.  15.  40.   8.  70.  75.]\n",
      "\n",
      "\n",
      "V335: 672\n",
      "[  nan    0.  145.  140.  125.   30.   20.   35.  302.   70.    6.   10.\n",
      "   50.   15.  130. 1129.  150.  200.  309.  250.]\n",
      "\n",
      "\n",
      "V336: 356\n",
      "[  nan    0.   25.   40.   35.   22.    6.   50.   15.   20.  400.  150.\n",
      "   60.   29.  100.   85. 1300.   95.    5.   65.]\n",
      "\n",
      "\n",
      "V337: 254\n",
      "[ nan   0.  50. 200. 100. 300. 500. 150.  30.  60.  65.  10.  25.  75.\n",
      " 125. 450. 120. 400. 600.  15.]\n",
      "\n",
      "\n",
      "V338: 380\n",
      "[ nan   0.  50. 200. 100. 300. 500.   8. 150.  30.  60.  65.  10.  40.\n",
      "  70.  25.  75. 125. 450. 120.]\n",
      "\n",
      "\n",
      "V339: 334\n",
      "[ nan   0.  50. 200. 100. 300. 500. 150.  30.  60.  65.  10.  25.  75.\n",
      " 125. 450. 120. 400. 600.  15.]\n",
      "\n",
      "\n",
      "id_01: 77\n",
      "[  nan    0.   -5.  -15.  -10.  -20.  -40.  -30.  -25.  -55.  -45.  -70.\n",
      "  -90. -100.  -65.  -60.  -75.  -72.  -50.  -21.]\n",
      "\n",
      "\n",
      "id_02: 115655\n",
      "[    nan  70787.  98945. 191631. 221832.   7460.  61141.  31964. 116098.\n",
      " 257037. 287959.  88525.  54927.  69542. 132356. 275611. 419136. 436352.\n",
      "  34810. 129080.]\n",
      "\n",
      "\n",
      "id_03: 24\n",
      "[ nan   0.   3.   2.   5.   1.   6.   9.   4.  -5.  -9.  -2.  -4.  -1.\n",
      "  -3.  -7.  -6. -11.   7.  -8.]\n",
      "\n",
      "\n",
      "id_04: 15\n",
      "[ nan   0. -11.  -5.  -8.  -1.  -6.  -9.  -3. -13.  -4. -10.  -7. -12.\n",
      "  -2. -28.]\n",
      "\n",
      "\n",
      "id_05: 93\n",
      "[ nan   0.   1.   3.   2.   9.  12.   6.   4.  21.   7.   5.  18.  17.\n",
      "  -1.  11.   8.  10. -10.  -8.]\n",
      "\n",
      "\n",
      "id_06: 101\n",
      "[  nan   -5.    0.   -6.  -10.  -11.   -1.   -4.  -43.   -9.  -44.  -33.\n",
      "  -29.   -8.  -81.  -13.  -24.  -17.  -32. -100.]\n",
      "\n",
      "\n",
      "id_07: 84\n",
      "[nan 22.  6. -1.  4.  2. 17. 12. 27.  5. 18. 16. 23. -4. 25. 20. 39. 21.\n",
      "  0. -9.]\n",
      "\n",
      "\n",
      "id_08: 94\n",
      "[  nan  -34.  -55. -100.  -15.  -33.  -13.  -36.  -44.  -26.  -20.  -18.\n",
      "  -50.  -43.  -32.  -49.   -7.  -46.  -27.  -25.]\n",
      "\n",
      "\n",
      "id_09: 46\n",
      "[ nan   0.   3.   2.   1.   5.  -8.   7.   4.   6.  -6.  -1.   9.  -7.\n",
      "  -4. -11. -22.  -2.  -5.  -9.]\n",
      "\n",
      "\n",
      "id_10: 62\n",
      "[ nan   0.  -9. -42.  -6. -29.  -8.  -1.  -5. -11. -16. -33.  -7. -30.\n",
      "  -4. -10. -27. -25. -21. -12.]\n",
      "\n",
      "\n",
      "id_11: 365\n",
      "[         nan 100.          93.75        95.08000183  95.65000153\n",
      "  94.29000092  96.19000244  90.56999969  97.54000092  96.43000031\n",
      "  98.31999969  98.91000366  94.12000275  94.19999695  96.19999695\n",
      "  96.23000336  93.55000305  94.68000031  90.91000366  94.05000305]\n",
      "\n",
      "\n",
      "id_12: 2\n",
      "[nan 'NotFound' 'Found']\n",
      "\n",
      "\n",
      "id_13: 54\n",
      "[nan 49. 52. 14. 20. 55. 43. 18. 41. 63. 61. 35. 25. 39. 57. 15. 11. 44.\n",
      " 62. 59.]\n",
      "\n",
      "\n",
      "id_14: 25\n",
      "[  nan -480. -300. -360. -420. -540. -600.  480. -240.  300. -180.   60.\n",
      "    0.  180.  540.  600.  420.  270.  120.  240.]\n",
      "\n",
      "\n",
      "id_15: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'New' 'Found' 'Unknown']\n",
      "\n",
      "\n",
      "id_16: 2\n",
      "[nan 'NotFound' 'Found']\n",
      "\n",
      "\n",
      "id_17: 104\n",
      "[ nan 166. 121. 225. 102. 148. 199. 146. 144. 133. 100. 130. 218. 150.\n",
      " 195. 153. 159. 142. 210. 200.]\n",
      "\n",
      "\n",
      "id_18: 18\n",
      "[nan 15. 18. 13. 12. 20. 21. 14. 26. 24. 17. 11. 29. 16. 28. 25. 23. 27.\n",
      " 10.]\n",
      "\n",
      "\n",
      "id_19: 522\n",
      "[ nan 542. 621. 410. 176. 529. 352. 484. 254. 278. 307. 266. 290. 548.\n",
      " 122. 215. 100. 345. 242. 193.]\n",
      "\n",
      "\n",
      "id_20: 394\n",
      "[ nan 144. 500. 142. 507. 575. 600. 533. 333. 549. 566. 305. 401. 391.\n",
      " 535. 325. 222. 277. 368. 597.]\n",
      "\n",
      "\n",
      "id_21: 490\n",
      "[ nan 252. 657. 724. 228. 369. 796. 755. 848. 734. 849. 596. 672. 255.\n",
      " 457. 164. 409. 130. 680. 510.]\n",
      "\n",
      "\n",
      "id_22: 25\n",
      "[nan 14. 41. 21. 33. 35. 19. 20. 31. 12. 36. 23. 28. 40. 24. 39. 22. 43.\n",
      " 26. 44.]\n",
      "\n",
      "\n",
      "id_23: 3\n",
      "[nan 'IP_PROXY:TRANSPARENT' 'IP_PROXY:ANONYMOUS' 'IP_PROXY:HIDDEN']\n",
      "\n",
      "\n",
      "id_24: 12\n",
      "[nan 11. 15. 16. 12. 21. 18. 25. 26. 19. 23. 24. 17.]\n",
      "\n",
      "\n",
      "id_25: 341\n",
      "[ nan 321. 161. 460. 426. 205. 268. 509. 132. 516. 485. 365. 501. 427.\n",
      " 356. 191. 514. 442. 525. 533.]\n",
      "\n",
      "\n",
      "id_26: 95\n",
      "[ nan 184. 102. 159. 142. 117. 191. 119. 121. 182. 100. 216. 147. 146.\n",
      " 133. 206. 161. 215. 169. 152.]\n",
      "\n",
      "\n",
      "id_27: 2\n",
      "[nan 'Found' 'NotFound']\n",
      "\n",
      "\n",
      "id_28: 2\n",
      "[nan 'New' 'Found']\n",
      "\n",
      "\n",
      "id_29: 2\n",
      "[nan 'NotFound' 'Found']\n",
      "\n",
      "\n",
      "id_30: 75\n",
      "[nan 'Android 7.0' 'iOS 11.1.2' 'Mac OS X 10_11_6' 'Windows 10' 'Android'\n",
      " 'Linux' 'iOS 11.0.3' 'Mac OS X 10_7_5' 'Mac OS X 10_12_6'\n",
      " 'Mac OS X 10_13_1' 'iOS 11.1.0' 'Mac OS X 10_9_5' 'Windows 7'\n",
      " 'Windows 8.1' 'Mac' 'iOS 10.3.3' 'Mac OS X 10.12' 'Mac OS X 10_10_5'\n",
      " 'Mac OS X 10_11_5']\n",
      "\n",
      "\n",
      "id_31: 130\n",
      "[nan 'samsung browser 6.2' 'mobile safari 11.0' 'chrome 62.0'\n",
      " 'chrome 62.0 for android' 'edge 15.0' 'mobile safari generic'\n",
      " 'chrome 49.0' 'chrome 61.0' 'edge 16.0' 'safari generic' 'edge 14.0'\n",
      " 'chrome 56.0 for android' 'firefox 57.0' 'chrome 54.0 for android'\n",
      " 'mobile safari uiwebview' 'chrome' 'chrome 62.0 for ios' 'firefox'\n",
      " 'chrome 60.0 for android']\n",
      "\n",
      "\n",
      "id_32: 4\n",
      "[nan 32. 24. 16.  0.]\n",
      "\n",
      "\n",
      "id_33: 260\n",
      "[nan '2220x1080' '1334x750' '1280x800' '1366x768' '1920x1080' '1680x1050'\n",
      " '1136x640' '5120x2880' '2880x1800' '1920x1200' '2560x1600' '2048x1536'\n",
      " '1024x768' '1280x720' '2560x1440' '2208x1242' '2001x1125' '1440x900'\n",
      " '1600x900']\n",
      "\n",
      "\n",
      "id_34: 4\n",
      "[nan 'match_status:2' 'match_status:1' 'match_status:0' 'match_status:-1']\n",
      "\n",
      "\n",
      "id_35: 2\n",
      "[nan 'T' 'F']\n",
      "\n",
      "\n",
      "id_36: 2\n",
      "[nan 'F' 'T']\n",
      "\n",
      "\n",
      "id_37: 2\n",
      "[nan 'T' 'F']\n",
      "\n",
      "\n",
      "id_38: 2\n",
      "[nan 'T' 'F']\n",
      "\n",
      "\n",
      "DeviceType: 2\n",
      "[nan 'mobile' 'desktop']\n",
      "\n",
      "\n",
      "DeviceInfo: 1786\n",
      "[nan 'SAMSUNG SM-G892A Build/NRD90M' 'iOS Device' 'Windows' 'MacOS'\n",
      " 'SM-G930V Build/NRD90M' 'BLADE A602 Build/MRA58K'\n",
      " 'XT1635-02 Build/NPN26.118-22-2' 'Z970' 'SM-N920V Build/NRD90M'\n",
      " 'Redmi Note 4 Build/MMB29M' 'Lenovo PB1-750M Build/S100'\n",
      " 'LT22i Build/6.2.A.1.100' 'rv:52.0' 'SM-G950U Build/NRD90M'\n",
      " 'LG-H872 Build/NRD90U' 'LG-K500 Build/MMB29M' 'SM-P550 Build/MMB29M'\n",
      " 'SM-J700M Build/MMB29K' 'Trident/7.0']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col, values in train.iteritems():\n",
    "    num_uniques = values.nunique()\n",
    "    print ('{name}: {num_unique}'.format(name=col, num_unique=num_uniques))\n",
    "    print (values.unique()[:min(20,len(values.unique()))])\n",
    "    print ('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_identity, train_transaction #, test_identity, test_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {train.isnull().any().sum()} columns in train dataset with missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_cols = [col for col in train.columns if train[col].nunique() <= 1]\n",
    "#one_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]\n",
    "#one_value_cols == one_value_cols_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(one_value_cols)} columns in train dataset with one unique value.')\n",
    "#print(f'There are {len(one_value_cols_test)} columns in test dataset with one unique value.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of columns have missing data, which is normal in real world. Also there are columns with one unique value (or all missing). There are a lot of continuous variables and some categorical. Let's have a closer look at them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Let's start with identity information.\n",
    "id_01 - id_11 are continuous variables, id_12 - id_38 are categorical and the last two columns are obviously also categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['id_01'], bins=77);\n",
    "plt.title('Distribution of id_01 variable');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`id_01` has an interesting distribution: it has 77 unique non-positive values with skeweness to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_03'].value_counts(dropna=False, normalize=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`id_03` has 88% of missing values and 98% of values are either missing or equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_11'].value_counts(dropna=False, normalize=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22% of values in `id_11` are equal to 100and 76% are missing. Quite strange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['id_07']);\n",
    "plt.title('Distribution of id_07 variable');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of features seem to be normalized. So if someone wants to normalize all variables, it would be necessary to separate such variables which seem to be already normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "charts = {}\n",
    "for i in ['id_12', 'id_15', 'id_16', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']:\n",
    "    feature_count = train[i].value_counts(dropna=False).reset_index().rename(columns={i: 'count', 'index': i})\n",
    "    chart = alt.Chart(feature_count).mark_bar().encode(\n",
    "                y=alt.Y(f\"{i}:N\", axis=alt.Axis(title=i)),\n",
    "                x=alt.X('count:Q', axis=alt.Axis(title='Count')),\n",
    "                tooltip=[i, 'count']\n",
    "            ).properties(title=f\"Counts of {i}\", width=400)\n",
    "    charts[i] = chart                         \n",
    "    \n",
    "render((charts['id_12'] | charts['id_15'] | charts['id_16']) & (charts['id_28'] | charts['id_29'] | charts['id_32']) & (charts['id_34'] | charts['id_35'] | charts['id_36']) & (charts['id_37'] | charts['id_38']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have several features showing some kind of \"found\" status and several binary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "charts = {}\n",
    "for i in ['id_30', 'id_31', 'id_33', 'DeviceType', 'DeviceInfo']:\n",
    "    feature_count = train[i].value_counts(dropna=False)[:40].reset_index().rename(columns={i: 'count', 'index': i})\n",
    "    chart = alt.Chart(feature_count).mark_bar().encode(\n",
    "                x=alt.X(f\"{i}:N\", axis=alt.Axis(title=i)),\n",
    "                y=alt.Y('count:Q', axis=alt.Axis(title='Count')),\n",
    "                tooltip=[i, 'count']\n",
    "            ).properties(title=f\"Counts of {i}\", width=800)\n",
    "    charts[i] = chart\n",
    "    \n",
    "render(charts['id_30'] & charts['id_31'] & charts['id_33'] & charts['DeviceType'] & charts['DeviceInfo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see some information about client's device. It is important to be careful here - some of info could be for old devices and may be absent from test data.\n",
    "\n",
    "Now let's have a look at transaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['TransactionDT'], label='train');\n",
    "#plt.hist(test['TransactionDT'], label='test');\n",
    "plt.legend();\n",
    "plt.title('Distribution of transactiond dates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important idea: it seems that train and test transaction dates don't overlap, so it would be prudent to use time-based split for validation.\n",
    "This was already noted in abother kernel: https://www.kaggle.com/robikscube/ieee-fraud-detection-first-look-and-eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "charts = {}\n",
    "for i in ['ProductCD', 'card4', 'card6', 'M4', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9']:\n",
    "    feature_count = train[i].value_counts(dropna=False).reset_index().rename(columns={i: 'count', 'index': i})\n",
    "    chart = alt.Chart(feature_count).mark_bar().encode(\n",
    "                y=alt.Y(f\"{i}:N\", axis=alt.Axis(title=i)),\n",
    "                x=alt.X('count:Q', axis=alt.Axis(title='Count')),\n",
    "                tooltip=[i, 'count']\n",
    "            ).properties(title=f\"Counts of {i}\", width=400)\n",
    "    charts[i] = chart                         \n",
    "    \n",
    "render((charts['ProductCD'] | charts['card4']) & (charts['card6'] | charts['M4']) & (charts['card6'] | charts['M4']) & (charts['M1'] | charts['M2']) & (charts['M3'] | charts['M5']) & (charts['M6'] | charts['M7']) & (charts['M8'] | charts['M9']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `card6` is type of card, `card4` is credit card company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "charts = {}\n",
    "for i in ['P_emaildomain', 'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2']:\n",
    "    feature_count = train[i].value_counts(dropna=False).reset_index()[:40].rename(columns={i: 'count', 'index': i})\n",
    "    chart = alt.Chart(feature_count).mark_bar().encode(\n",
    "                x=alt.X(f\"{i}:N\", axis=alt.Axis(title=i)),\n",
    "                y=alt.Y('count:Q', axis=alt.Axis(title='Count')),\n",
    "                tooltip=[i, 'count']\n",
    "            ).properties(title=f\"Counts of {i}\", width=600)\n",
    "    charts[i] = chart\n",
    "    \n",
    "render((charts['P_emaildomain'] | charts['R_emaildomain']) & (charts['card1'] | charts['card2']) & (charts['card3'] | charts['card5']) & (charts['addr1'] | charts['addr2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Let's create some aggregations. There is no logic in them - simply aggregations on top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "'''\n",
    "test['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "'''\n",
    "train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "train['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "train['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n",
    "'''\n",
    "test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "test['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "test['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n",
    "'''\n",
    "train['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "'''test['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n",
    "'''\n",
    "train['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "'''test['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train['P_emaildomain'].str.split('.', expand=True)\n",
    "train[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train['R_emaildomain'].str.split('.', expand=True)\n",
    "'''test[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test['P_emaildomain'].str.split('.', expand=True)\n",
    "test[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test['R_emaildomain'].str.split('.', expand=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\n",
    "#many_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop if one value is >90% of the column\n",
    "big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "#big_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols+ one_value_cols_test))\n",
    "cols_to_drop = list(set(many_null_cols + big_top_value_cols + one_value_cols ))\n",
    "cols_to_drop.remove('isFraud')\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(cols_to_drop, axis=1)\n",
    "#test = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n",
    "            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n",
    "            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9',\n",
    "            'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']\n",
    "for col in cat_cols:\n",
    "    if col in train.columns:\n",
    "        le = LabelEncoder()\n",
    "#        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        le.fit(list(train[col].astype(str).values) )\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "#        test[col] = le.transform(list(test[col].astype(str).values))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']\n",
    "#X_test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)\n",
    "del train\n",
    "#test = test[[\"TransactionDT\", 'TransactionID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "folds = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 256,\n",
    "          'min_child_samples': 79,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': 13,\n",
    "          'learning_rate': 0.03,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 3,\n",
    "          \"subsample\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3,\n",
    "          'reg_lambda': 0.3,\n",
    "          'colsample_bytree': 0.9,\n",
    "          #'categorical_feature': cat_cols\n",
    "         }\n",
    "result_dict_lgb = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='auc', plot_feature_importance=True,\n",
    "                                                      verbose=500, early_stopping_rounds=200, n_estimators=5000, averaging='usual', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values('TransactionDT')\n",
    "test['prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['isFraud'] = pd.merge(sub, test, on='TransactionID')['prediction']\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_dict_lgb['oof']).to_csv('lgb_oof.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test memory reduction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
